{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images found: 441\n",
      "torch.Size([64, 3, 224, 224])\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# List of possible image extensions\n",
    "image_formats = {'.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG', '.heic', '.HEIC'}\n",
    "\n",
    "def get_image_files(patient_path):\n",
    "    \"\"\" Get all image files in a patient's folder \"\"\"\n",
    "    image_files = []\n",
    "    for file in os.listdir(patient_path):\n",
    "        if any(file.lower().endswith(ext) for ext in image_formats):\n",
    "            image_files.append(os.path.join(patient_path, file))\n",
    "    return image_files\n",
    "\n",
    "class AnemiaDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Walk through the dataset directories (IRON DEFICIENCY ANEMIA and NON - IRON DEFICIENCY ANEMIA)\n",
    "        for condition in ['IRON DEFICIENCY ANEMIA', 'NON - IRON DEFICIENCY ANEMIA']:\n",
    "            condition_path = os.path.join(data_dir, condition)\n",
    "            if not os.path.exists(condition_path):\n",
    "                continue\n",
    "            \n",
    "            # Iterate through each patient folder\n",
    "            for patient_folder in os.listdir(condition_path):\n",
    "                patient_path = os.path.join(condition_path, patient_folder)\n",
    "                if os.path.isdir(patient_path):\n",
    "                    # Get all image files for the patient (regardless of their name)\n",
    "                    img_files = get_image_files(patient_path)\n",
    "                    \n",
    "                    # If any images are found, add them to the dataset\n",
    "                    for img_path in img_files:\n",
    "                        self.image_paths.append(img_path)\n",
    "                        # Set label: 1 for \"IRON DEFICIENCY ANEMIA\", 0 for \"NON - IRON DEFICIENCY ANEMIA\"\n",
    "                        self.labels.append(1 if condition == 'IRON DEFICIENCY ANEMIA' else 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load the image\n",
    "        image = Image.open(img_path).convert('RGB')  # Ensure it's RGB format\n",
    "        \n",
    "        # Apply any transformations (resize, normalize, etc.)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Define the transformations to apply to each image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 pixels (common input size for CNNs)\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization (ImageNet values)\n",
    "])\n",
    "\n",
    "# Define the path to your dataset\n",
    "dataset_dir = r\".\\real_data\"\n",
    "\n",
    "# Create the custom dataset\n",
    "dataset = AnemiaDataset(data_dir=dataset_dir, transform=transform)\n",
    "\n",
    "# Print the total number of images found\n",
    "print(f\"Total number of images found: {len(dataset)}\")\n",
    "\n",
    "# Split the dataset into training and validation\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = len(dataset) - train_size  # 20% for validation\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Example of how to access the data\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape)  # Batch of images\n",
    "    print(labels)        # Corresponding labels\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projs\\anemia_project\\cudavenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\projs\\anemia_project\\cudavenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extracting Features: 100%|██████████| 6/6 [00:14<00:00,  2.36s/it]\n",
      "Extracting Features: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "device='cuda'\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet.fc = torch.nn.Identity()  # Remove the last fully connected layer (so we get features)\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(data_loader, model, device):\n",
    "    features = []\n",
    "    labels_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Extracting Features\"):\n",
    "            images = images.to(device)\n",
    "            output = model(images)  # Extract features\n",
    "            \n",
    "            features.append(output.cpu().numpy())  # Move to CPU and convert to NumPy\n",
    "            labels_list.append(labels.cpu().numpy())\n",
    "    \n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels_list, axis=0)\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "# Extract features from training and validation sets\n",
    "train_features, train_labels = extract_features(train_loader, resnet, device)\n",
    "val_features, val_labels = extract_features(val_loader, resnet, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 83.15%\n",
      "SVM Accuracy: 86.52%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train Logistic Regression\n",
    "logistic_clf = LogisticRegression(max_iter=1000)\n",
    "logistic_clf.fit(train_features, train_labels)\n",
    "\n",
    "# Validate Logistic Regression\n",
    "logistic_preds = logistic_clf.predict(val_features)\n",
    "logistic_accuracy = accuracy_score(val_labels, logistic_preds)\n",
    "print(f\"Logistic Regression Accuracy: {logistic_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Train Support Vector Machine (SVM)\n",
    "svm_clf = SVC(kernel='poly')  # You can change kernel to 'rbf', 'poly', etc.\n",
    "svm_clf.fit(train_features, train_labels)\n",
    "\n",
    "# Validate SVM\n",
    "svm_preds = svm_clf.predict(val_features)\n",
    "svm_accuracy = accuracy_score(val_labels, svm_preds)\n",
    "print(f\"SVM Accuracy: {svm_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizations saved in ml_visualizations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def visualize_ml_models(logistic_clf, svm_clf, \n",
    "                         train_features, train_labels, \n",
    "                         val_features, val_labels, \n",
    "                         save_dir='ml_visualizations'):\n",
    "    # Create visualizations directory\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Predictions\n",
    "    logistic_preds = logistic_clf.predict(val_features)\n",
    "    svm_preds = svm_clf.predict(val_features)\n",
    "    \n",
    "    # Performance comparison plot\n",
    "    plt.figure(figsize=(12, 5), facecolor='#2C3E50')\n",
    "    plt.style.use('dark_background')\n",
    "    \n",
    "    # Bar plot for model accuracies\n",
    "    models = ['Logistic Regression', 'Support Vector Machine']\n",
    "    accuracies = [\n",
    "        accuracy_score(val_labels, logistic_preds) * 100,\n",
    "        accuracy_score(val_labels, svm_preds) * 100\n",
    "    ]\n",
    "    \n",
    "    plt.bar(models, accuracies, color=['#3498DB', '#E74C3C'])\n",
    "    plt.title('Model Performance Comparison', color='white', fontsize=15)\n",
    "    plt.ylabel('Accuracy (%)', color='white')\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    # Add accuracy values on top of bars\n",
    "    for i, acc in enumerate(accuracies):\n",
    "        plt.text(i, acc+1, f'{acc:.2f}%', \n",
    "                 horizontalalignment='center', \n",
    "                 color='white', \n",
    "                 fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'model_accuracy_comparison.png'), \n",
    "                facecolor='#2C3E50', \n",
    "                edgecolor='none', \n",
    "                dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Confusion Matrices\n",
    "    plt.figure(figsize=(12, 5), facecolor='#2C3E50')\n",
    "    plt.style.use('dark_background')\n",
    "    \n",
    "    # Logistic Regression Confusion Matrix\n",
    "    plt.subplot(1, 2, 1)\n",
    "    cm_logistic = confusion_matrix(val_labels, logistic_preds)\n",
    "    sns.heatmap(cm_logistic, annot=True, fmt='d', cmap='Blues', \n",
    "                cbar=False, square=True)\n",
    "    plt.title('Logistic Regression\\nConfusion Matrix', color='white')\n",
    "    plt.xlabel('Predicted', color='white')\n",
    "    plt.ylabel('Actual', color='white')\n",
    "    \n",
    "    # SVM Confusion Matrix\n",
    "    plt.subplot(1, 2, 2)\n",
    "    cm_svm = confusion_matrix(val_labels, svm_preds)\n",
    "    sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Reds', \n",
    "                cbar=False, square=True)\n",
    "    plt.title('SVM\\nConfusion Matrix', color='white')\n",
    "    plt.xlabel('Predicted', color='white')\n",
    "    plt.ylabel('Actual', color='white')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'confusion_matrices.png'), \n",
    "                facecolor='#2C3E50', \n",
    "                edgecolor='none', \n",
    "                dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Classification Reports\n",
    "    report_logistic = classification_report(val_labels, logistic_preds)\n",
    "    report_svm = classification_report(val_labels, svm_preds)\n",
    "    \n",
    "    with open(os.path.join(save_dir, 'classification_reports.txt'), 'w') as f:\n",
    "        f.write(\"LOGISTIC REGRESSION REPORT\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(report_logistic + \"\\n\\n\")\n",
    "        f.write(\"SVM REPORT\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(report_svm)\n",
    "    \n",
    "    print(f\"Visualizations saved in {save_dir}\")\n",
    "\n",
    "# Usage would be:\n",
    "visualize_ml_models(logistic_clf, svm_clf, \n",
    "                    train_features, train_labels, \n",
    "                    val_features, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
