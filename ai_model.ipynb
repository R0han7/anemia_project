{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define custom dataset class\n",
    "class AnemiaDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Load image filenames and their corresponding labels\n",
    "        for filename in os.listdir(data_dir):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png')):  # Check for image files\n",
    "                # Check if the image name starts with \"Anemic\" or \"Non-Anemic\"\n",
    "                if filename.startswith(\"Anemic\"):\n",
    "                    label = 1  # Anemic\n",
    "                elif filename.startswith(\"Non-Anemic\"):\n",
    "                    label = 0  # Non-Anemic\n",
    "                else:\n",
    "                    continue  # Skip images with unexpected filenames\n",
    "                \n",
    "                # Append the full path and label\n",
    "                self.image_paths.append(os.path.join(data_dir, filename))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load the image\n",
    "        image = Image.open(img_path).convert('RGB')  # Ensure 3 channels (RGB)\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define the transform to resize and normalize images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard ImageNet normalization\n",
    "])\n",
    "\n",
    "# Define the path to the data folder\n",
    "dataset_dir = r\".\\anemia_detection\\Palm\"\n",
    "\n",
    "# Create custom dataset\n",
    "dataset = AnemiaDataset(data_dir=dataset_dir, transform=transform)\n",
    "\n",
    "# Split dataset into training and validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projs\\anemia_project\\cudavenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\projs\\anemia_project\\cudavenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# Load pre-trained ResNet50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer for binary classification (2 classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, 1)  # Output size = 1 for binary classification\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # For binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.0093, Train Accuracy: 0.9981, Val Loss: 0.0478, Val Accuracy: 0.9815\n",
      "Epoch [2/10], Train Loss: 0.0117, Train Accuracy: 0.9957, Val Loss: 0.0437, Val Accuracy: 0.9840\n",
      "Epoch [3/10], Train Loss: 0.0154, Train Accuracy: 0.9948, Val Loss: 0.0437, Val Accuracy: 0.9827\n",
      "Epoch [4/10], Train Loss: 0.0126, Train Accuracy: 0.9960, Val Loss: 0.0465, Val Accuracy: 0.9790\n",
      "Epoch [5/10], Train Loss: 0.0091, Train Accuracy: 0.9985, Val Loss: 0.0454, Val Accuracy: 0.9840\n",
      "Epoch [6/10], Train Loss: 0.0133, Train Accuracy: 0.9969, Val Loss: 0.0478, Val Accuracy: 0.9840\n",
      "Epoch [7/10], Train Loss: 0.0124, Train Accuracy: 0.9963, Val Loss: 0.0475, Val Accuracy: 0.9815\n",
      "Epoch [8/10], Train Loss: 0.0111, Train Accuracy: 0.9969, Val Loss: 0.0461, Val Accuracy: 0.9815\n",
      "Epoch [9/10], Train Loss: 0.0096, Train Accuracy: 0.9978, Val Loss: 0.0472, Val Accuracy: 0.9815\n",
      "Epoch [10/10], Train Loss: 0.0114, Train Accuracy: 0.9972, Val Loss: 0.0453, Val Accuracy: 0.9864\n",
      "Training complete.\n",
      "Best Validation Accuracy: 0.9864\n"
     ]
    }
   ],
   "source": [
    "# Function to train the model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to('cuda' if torch.cuda.is_available() else 'cpu'), labels.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze()  # Remove extra dimensions for binary classification\n",
    "            loss = criterion(outputs, labels.float())  # Compute loss\n",
    "            loss.backward()  # Backpropagate\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute accuracy\n",
    "            predicted = torch.round(torch.sigmoid(outputs))  # Get predictions\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy and loss\n",
    "        train_accuracy = correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Evaluate on validation data\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to('cuda' if torch.cuda.is_available() else 'cpu'), labels.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.squeeze()\n",
    "\n",
    "                # Compute loss and accuracy\n",
    "                loss = criterion(outputs, labels.float())\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predicted = torch.round(torch.sigmoid(outputs))\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Print results for this epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Save the best model based on validation accuracy\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), 'best_model.pt',_use_new_zipfile_serialization=True,pickle_protocol=4)\n",
    "            torch.save(model.state_dict(), 'best_model.pth',_use_new_zipfile_serialization=True,pickle_protocol=4)\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    print(f\"Best Validation Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_7524\\2410240957.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Accuracy: 0.9852\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to('cuda' if torch.cuda.is_available() else 'cpu'), labels.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze()\n",
    "\n",
    "        predicted = torch.round(torch.sigmoid(outputs))\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Final Validation Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'_____________________________________'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projs\\anemia_project\\cudavenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\projs\\anemia_project\\cudavenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_7524\\1087447240.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))  # Load the saved weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person is predicted to be: Non-Anemic\n",
      "Prediction probability: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Function to load the trained model\n",
    "def load_model(model_path='best_model.pth'):\n",
    "    # Load pre-trained ResNet50 model and modify for binary classification\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 1)  # Output size = 1 for binary classification\n",
    "    model.load_state_dict(torch.load(model_path))  # Load the saved weights\n",
    "    model = model.to('cuda' if torch.cuda.is_available() else 'cpu')  # Move to GPU if available\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Define the transforms (same as used in training)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize the image to 224x224\n",
    "        transforms.ToTensor(),  # Convert the image to a Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize based on ImageNet stats\n",
    "    ])\n",
    "\n",
    "    # Open the image file and apply the transformations\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure the image is in RGB format\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add a batch dimension\n",
    "    return image\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_anemia(model, image_path):\n",
    "    # Preprocess the input image\n",
    "    image = preprocess_image(image_path)\n",
    "    \n",
    "    # Move image to the same device as the model (GPU or CPU)\n",
    "    image = image.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Forward pass through the model to get the prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(image)  # Output is a single value\n",
    "\n",
    "    # Apply sigmoid to the output to get a probability\n",
    "    probability = torch.sigmoid(output).item()  # Convert the output to a scalar probability\n",
    "\n",
    "    # If the probability is greater than 0.5, we classify it as \"Anemic\" (1)\n",
    "    if probability > 0.5:\n",
    "        return \"Anemic\", probability\n",
    "    else:\n",
    "        return \"Non-Anemic\", probability\n",
    "\n",
    "# Example usage of the functions\n",
    "if __name__ == '__main__':\n",
    "    image_path = r'C:\\projs\\anemia_project\\Non-AnemicP-040 (5).png'\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model()\n",
    "\n",
    "    # Make prediction on the input image\n",
    "    label, probability = predict_anemia(model, image_path)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"The person is predicted to be: {label}\")\n",
    "    print(f\"Prediction probability: {probability:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
